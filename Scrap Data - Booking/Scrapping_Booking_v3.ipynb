{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f79a9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#!pip3 install -r requirements.txt\n",
    "#import dropbox\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# auxiliary functions modified by Luis.\n",
    "import scrape_functions as kzd\n",
    "import sys\n",
    "import calendar\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "import re\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import random\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(sys.modules['scrape_functions'])\n",
    "from datetime import date\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c0a6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# %% Starting code\n",
    "cities = ['Paris', 'Barcelona']\n",
    "\n",
    "i=0\n",
    "for place in cities:\n",
    "    if place == 'Barcelona':\n",
    "        i=0\n",
    "    check_in_date = [\"2023-05-15\", \"2023-05-29\"]\n",
    "    check_out_date = [\"2023-05-21\", \"2023-06-04\"]\n",
    "    \n",
    "    for d in check_in_date:\n",
    "        dfolder = 'out'\n",
    "        link = 'https://www.booking.com/'\n",
    "        profile, browser, download_path = kzd.start_up(dfolder, link, download=True) \n",
    "\n",
    "        search1 = browser.find_element('xpath','//input[@placeholder=\"Where are you going?\"]')\n",
    "        search1.send_keys(place)\n",
    "\n",
    "        kzd.check_and_click(browser,'//button[@type=\"submit\"]', type='xpath')\n",
    "        print('main search button clicked')\n",
    "\n",
    "        time.sleep(2)\n",
    "        week=[check_in_date[i], check_out_date[i]]\n",
    "        today_month = 2\n",
    "        while today_month < int(week[0].split('-')[1]):\n",
    "            time.sleep(2)\n",
    "            dates = browser.find_elements('xpath','//table[@class=\"aadb8ed6d3\"]/tbody/tr/td/span')\n",
    "            print('dates: ', len(dates))\n",
    "            kzd.check_and_click(browser, '//button[@class=\"fc63351294 a822bdf511 e3c025e003 fa565176a8 cfb238afa1 ae1678b153 c9fa5fc96d be298b15fa\"]', type='xpath')\n",
    "            print('month clicked')\n",
    "            today_month+=1\n",
    "\n",
    "\n",
    "        #%%\n",
    "        def scrollDown(driver, numberOfScrollDowns):\n",
    "            body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "            while numberOfScrollDowns >= 0:\n",
    "                body.send_keys(Keys.PAGE_DOWN)\n",
    "                numberOfScrollDowns -= 1\n",
    "            return driver\n",
    "\n",
    "        #%%\n",
    "        scrollDown(browser, 0.05)\n",
    "\n",
    "        e = browser.find_element(By.XPATH, '//span[@data-date=\"{}\"]'.format(week[0]))\n",
    "        browser.execute_script(\"arguments[0].click()\", e)\n",
    "\n",
    "        e = browser.find_element(By.XPATH, '//span[@data-date=\"{}\"]'.format(week[1]))\n",
    "        browser.execute_script(\"arguments[0].click()\", e)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # click on empty space\n",
    "        kzd.check_and_click(\n",
    "            browser, '//input[@class=\"ce45093752\"]', type='xpath')\n",
    "        print('blank space clicked')\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        kzd.check_and_click(browser,'//button[@type=\"submit\"]', type='xpath')\n",
    "        print('search button clicked')\n",
    "\n",
    "        time.sleep(1)\n",
    "        def get_number_pages(browser):\n",
    "            '''\n",
    "            Get the number of pages. \n",
    "            '''\n",
    "            a = browser.find_elements('xpath',\n",
    "                '//button[text() and @class=\"fc63351294 f9c5690c58\"]')\n",
    "            total_pages = int(a[-1].text)\n",
    "            time.sleep(1)\n",
    "            return(total_pages)\n",
    "\n",
    "        pages = get_number_pages(browser)\n",
    "        print('total pages: ', pages)\n",
    "        #%%\n",
    "\n",
    "        def BookingReport(deal_boxes):\n",
    "            page_report = []\n",
    "            for deal_box in deal_boxes:\n",
    "                hotel_name = deal_box.find_element(By.CSS_SELECTOR,\n",
    "                    'div[data-testid=\"title\"]'\n",
    "                ).get_attribute('innerHTML').strip()\n",
    "\n",
    "                if not deal_box.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"price-and-discounted-price\"]'):\n",
    "                    hotel_price = deal_box.find_element(By.CSS_SELECTOR,\n",
    "                        'div[data-testid=\"price-and-discounted-price\"]'\n",
    "                    ).find_element(By.TAG_NAME, 'div').get_attribute('innerHTML').strip()\n",
    "                else:\n",
    "                    hotel_price = deal_box.find_element(By.CSS_SELECTOR,\n",
    "                        'span[data-testid=\"price-and-discounted-price\"]'\n",
    "                    ).get_attribute('innerHTML').strip()\n",
    "                    hotel_price = hotel_price.replace(\"€&nbsp;\", \"\")\n",
    "                    hotel_price = hotel_price.replace(\",\", \"\")\n",
    "                    hotel_price = int(hotel_price)\n",
    "\n",
    "                try:\n",
    "                    hotel_score = deal_box.find_element(By.CSS_SELECTOR,\n",
    "                        'div[aria-label*=\"Scored\"]'\n",
    "                    ).get_attribute('innerHTML').strip()\n",
    "                except:\n",
    "                    hotel_score = 'nan'\n",
    "                page_report.append(\n",
    "                    [hotel_name, hotel_price, hotel_score]\n",
    "                )\n",
    "                # print([hotel_name, hotel_price, hotel_score])\n",
    "            return page_report\n",
    "\n",
    "        #%%        \n",
    "        # Loop pages\n",
    "        full_report = []\n",
    "\n",
    "        for page in range(pages):\n",
    "            # Get the list of hotel elements on the page\n",
    "\n",
    "            print('Scraping page {} out of {}...'.format(page+1, pages))\n",
    "            print('before: ', len(full_report))\n",
    "\n",
    "            browser.implicitly_wait(2)\n",
    "\n",
    "            deal_boxes = browser.find_elements(\n",
    "                    By.XPATH,\n",
    "                    \"//div[@data-testid='property-card']\"\n",
    "                    )\n",
    "            report = BookingReport(deal_boxes)\n",
    "            time.sleep(4)\n",
    "\n",
    "            full_report.extend(report)\n",
    "\n",
    "            print('after: ', len(full_report))\n",
    "\n",
    "            scrollDown(browser, 1.5)\n",
    "\n",
    "\n",
    "            kzd.check_and_click(browser, \n",
    "                '//button[@aria-label=\"Next page\"]', \n",
    "                type='xpath' )\n",
    "\n",
    "            time.sleep(4)\n",
    "\n",
    "        report_df = pd.DataFrame(full_report)\n",
    "\n",
    "        # %%\n",
    "        deal_boxes = browser.find_elements(\n",
    "                    By.XPATH,\n",
    "                    \"//div[@data-testid='property-card']\"\n",
    "                    )\n",
    "\n",
    "        report = BookingReport(deal_boxes)\n",
    "        report_df = pd.DataFrame(full_report, columns=['hotel','price','rating'])\n",
    "        report_df['start_date'] = week[0]\n",
    "        report_df['city']=place\n",
    "        df = report_df.copy()\n",
    "        j=0\n",
    "        for r in df['price']:\n",
    "            if type(r) is int:\n",
    "                pass\n",
    "            else:\n",
    "                df['price'][j] = df['price'][j].replace(\"Price €&nbsp;\", \"\")\n",
    "                df['price'][j] = df['price'][j].replace(\",\", \"\")\n",
    "                df['price'][j] = int(df['price'][j])\n",
    "            j+=1\n",
    "        df.to_csv('scrape{}v2.csv'.format(place+week[0]))\n",
    "        i+=1\n",
    "df1 = pd.read_csv('scrapeParis2023-05-15v2.csv')\n",
    "df2 = pd.read_csv('scrapeParis2023-05-29v2.csv')\n",
    "df3 = pd.read_csv('scrapeBarcelona2023-05-15v2.csv')\n",
    "df4 = pd.read_csv('scrapeBarcelona2023-05-29v2.csv')\n",
    "df1 = df1.append(df2)\n",
    "df1 = df1.append(df3)\n",
    "df1 = df1.append(df4)\n",
    "df1.to_csv('scrape_all_cities.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
